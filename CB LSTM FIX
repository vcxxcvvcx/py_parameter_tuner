# 0. 라이브러리 임포트 및 시드 고정
import os
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import tensorflow as tf

def set_seed(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    tf.config.threading.set_inter_op_parallelism_threads(1)
    tf.config.threading.set_intra_op_parallelism_threads(1)

set_seed(42)

# 1. 데이터 로드
data = pd.read_csv(r'C:\Users\user\Desktop\오늘파일\엠티\cbkp.txt', delimiter='\t', header=None,
                   names=['Date', 'Open', 'High', 'Low', 'Close'])

# 2. 파생 변수 생성
data['OC'] = abs(data['Open'] - data['Close'])
data['NOC'] = (data['High'] - data['Low']) - data['OC']
data['HC_LC'] = data.apply(lambda row: max(row['High'] - row['Close'], row['Close'] - row['Low']), axis=1)
data['OH_OL'] = data.apply(lambda row: max(row['High'] - row['Open'], row['Open'] - row['Low']), axis=1)
data['OC_NOC'] = data.apply(lambda row: max(row['OC'], row['NOC']), axis=1)
data['HC_LC_OH_OL'] = data.apply(lambda row: max(row['HC_LC'], row['OH_OL']), axis=1)
data['HC_LC_OC_NOC'] = data.apply(lambda row: max(row['HC_LC'], row['OC_NOC']), axis=1)
data['OH_OL_OC_NOC'] = data.apply(lambda row: max(row['OH_OL'], row['OC_NOC']), axis=1)
data['HC_LC_OH_OL_OC_NOC'] = data.apply(lambda row: max(row['HC_LC'], row['OH_OL'], row['OC_NOC']), axis=1)

# 3. 피처 선택 및 정규화
features = ['Open', 'High', 'Low', 'Close', 'HC_LC_OH_OL_OC_NOC']
scaler_all = MinMaxScaler()
scaled_all = scaler_all.fit_transform(data[features])

scaler_close = MinMaxScaler()
scaled_close = scaler_close.fit_transform(data[['Close']])

# 4. 시퀀스 생성
def create_sequences(feature_data, close_data, lookback=30):
    X, y = [], []
    for i in range(len(feature_data) - lookback):
        X.append(feature_data[i:i+lookback])
        y.append(close_data[i+lookback])
    return np.array(X), np.array(y)

X, y = create_sequences(scaled_all, scaled_close)

# 5. LSTM 모델 정의 및 학습
model = Sequential([
    LSTM(64, return_sequences=False, input_shape=(X.shape[1], X.shape[2])),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1, shuffle=True, verbose=1)

# 6. 예측 및 역정규화
predicted_scaled = model.predict(X)
predicted_close = scaler_close.inverse_transform(predicted_scaled).flatten()

# 7. 실제값과 예측값 정렬
actual_close = data['Close'].values[-len(predicted_close):]

# 8. 시각화
plt.figure(figsize=(12, 6))
plt.plot(actual_close, label='Actual Close')
plt.plot(predicted_close, label='Predicted Close')
plt.title("LSTM Close Price Prediction")
plt.xlabel("Time Step")
plt.ylabel("Close Price")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 9. 결과 분석 메시지
final_actual = actual_close[-1]
final_predicted = predicted_close[-1]
mae = np.mean(np.abs(actual_close - predicted_close))

print("\n📊 예측 결과 요약")
print(f"• 마지막 실제 종가: {final_actual:.2f}")
print(f"• 마지막 예측 종가: {final_predicted:.2f}")
print(f"• 평균 절대 오차(MAE): {mae:.2f}")

if final_predicted > final_actual:
    print("📈 LSTM은 다음 종가가 상승할 가능성이 있다고 예측합니다.")
elif final_predicted < final_actual:
    print("📉 LSTM은 다음 종가가 하락할 가능성이 있다고 예측합니다.")
else:
    print("➖ LSTM은 종가가 현재 수준을 유지할 것으로 보고 있습니다.")


# 📊 예측 결과 요약 TR1 AM 25 06 23
# • 마지막 실제 종가: 345.15
# • 마지막 예측 종가: 346.63
# • 평균 절대 오차(MAE): 2.76
# 📈 LSTM은 다음 종가가 상승할 가능성이 있다고 예측합니다.

# 📊 예측 결과 요약 TR2 AM 25 06 23
# • 마지막 실제 종가: 345.15
# • 마지막 예측 종가: 346.63
# • 평균 절대 오차(MAE): 2.76
# 📈 LSTM은 다음 종가가 상승할 가능성이 있다고 예측합니다.

# 📊 예측 결과 요약 TR3 AM 25 06 23
# • 마지막 실제 종가: 345.15
# • 마지막 예측 종가: 346.63
# • 평균 절대 오차(MAE): 2.76
# 📈 LSTM은 다음 종가가 상승할 가능성이 있다고 예측합니다.
